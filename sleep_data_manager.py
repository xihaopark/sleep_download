#!/usr/bin/env python3
"""
Sleep Data è‡ªåŠ¨åŒ–ç®¡ç†å™¨
åŠŸèƒ½ï¼š
1. å¹¶è¡Œä¸‹è½½æ–‡ä»¶
2. å¹¶è¡Œä¸Šä¼ åˆ°Dropbox
3. è‡ªåŠ¨çŠ¶æ€ç®¡ç†
4. æ™ºèƒ½é‡è¯•æœºåˆ¶
5. ç£ç›˜ç©ºé—´ç›‘æ§

ä¸€é”®æ‰§è¡Œï¼Œæ— éœ€é¢å¤–é…ç½®
"""

import os
import sys
import threading
import time
import requests
import json
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import shutil

class SleepDataManager:
    def __init__(self):
        # Dropboxé…ç½® - å†…ç½®ä»¤ç‰Œ
        self.dropbox_token = "sl.u.AF34PeTlpglqeAYwABIYfeD3-SyW3tTUqkcjG_o5ffO0YJ9nT_G2pd1wHYFRqqv7z0-LFZ6jg6soFpe3KCUNDqulVlMPIWG-Mf80Jvbw72x6S9NJV-5-0IbRcXFeG7ktJWGjMFs5ynvdoFkJtzAZ9cMS3nvKk9Poqg-APtUA7IciNIDS3xa17WBDpBMg33z4Qm2FRaVgcNtu9OZ23zS7s0aNxX-SaKcWtElePah0seAESpGhHgtKTmnSOK3pt0gs5W0PqcmPw8p0y_euTs6_BGkQvieK_WdCzaOVP8Cs0dl1ep7IIYilmlEHw1HoXHstC-4oQJsIf7UFBaPNufbushoXDPftGh7wsFiW2x2c62fKDk1PtKh5B2MW2k1ZcMMK6QHom9bdFtagQ9mFSZV85stQkmNgXY2fMGaKbiMSLaNsv0BKYijWT6SEbQHAZSai6yMNn2rfWkVu_WjvaQrqTVme0WCtvNq_vhtkidxvLGQ1zDVqz-7b_JVhAGgg8gdzUk0DUUHq-HRKsg9WIgXmnn28j6exYVYqBxPxdAkL_m953kWKZKSIqcERKkjd-z7OP6VV-gdP0abDHFg8KnhZNJJufC_MG0Va1e_m4FAzMGVmNWO5Io9abHOrvDc2RyHyegVc-KZoeLZCwcov1JOhad1sPuJwvCTKDNqTNLhfLArlYYgbAygRhEI0VWNYDUnEgwov3cCcFqAPKWhGrcCQvdphhDy0AXht6-_DSqR1H36OrNfOkyypxTJzWLJ_GMh7U0M58grI0lpW5ecA0PcIy0U6Vze_Io29c8V4lZhNSSibtUevKyUa_Cg6-ay-xBiCBSPhbnc840-n-jPiK0manr55ruct-_tsFMuBtoa5S4UvDVdhuq2iT770DBmeriJDWrtfKdnc7ZxKUk_Wh18kMFyM995igTxyLuejytQhAUhbuWiMlTHik01m2382_H_yOwwpZ-wU0-EXp7_VatSEPJWPSAO3MJgCuc8y8Fdnk10MY6BzKc3EpbIbJtnIzTsxLiLu2aWklgzwuGkt_HsolNKgKTYEpqYvdT8gWZBBKUl9p9ETqP_lEkGfQ6j1RdXsSvtMiWJGl7xje6g5cwLfuwwXdMyly_PugCxdySaiuLQACguUpvk-M52P9Pgigu3cKxbuviy7mhT-bWdGLOo1FLqnHNTYkdY45-aMjL5JNL2i_ZdKNTgNuvseNd4C-uegmY6qXrpnOMO2uSxHe-p9JI2Sy9qo2_K-PWU5Bpp-3IQ6MsuVuSoC_IOWbpWtn9kG6g92FxNq9OyiVLNB6XZ-ozgeilEaelnkSs9lHk3dSt_dWw"
        
        # è·¯å¾„é…ç½®
        self.download_dir = Path("download")
        self.download_dir.mkdir(exist_ok=True)
        
        # çŠ¶æ€æ–‡ä»¶
        self.uploaded_log = "uploaded_files.txt"
        self.download_queue_file = "download_queue.txt"
        self.failed_downloads_file = "failed_downloads.txt"
        
        # å¹¶å‘é…ç½®
        self.max_download_threads = 3
        self.max_upload_threads = 2
        self.chunk_size = 100 * 1024 * 1024  # 100MB chunks
        
        # åŸºç¡€URL
        self.base_url = "https://physionet.org/files/nch-sleep/3.1.0/Sleep_Data/"
        
        # é˜Ÿåˆ—
        self.download_queue = queue.Queue()
        self.upload_queue = queue.Queue()
        
        # ç»Ÿè®¡
        self.stats = {
            'downloaded': 0,
            'uploaded': 0,
            'failed': 0,
            'total_downloaded_size': 0,
            'total_uploaded_size': 0
        }
        
        # é”
        self.stats_lock = threading.Lock()
        self.file_lock = threading.Lock()
        
        print("ğŸš€ Sleep Data Manager åˆå§‹åŒ–å®Œæˆ")

    def load_existing_state(self):
        """åŠ è½½ç°æœ‰çŠ¶æ€"""
        print("ğŸ“Š åŠ è½½ç°æœ‰çŠ¶æ€...")
        
        # åŠ è½½å·²ä¸Šä¼ æ–‡ä»¶
        uploaded_files = set()
        if os.path.exists(self.uploaded_log):
            with open(self.uploaded_log, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        uploaded_files.add(line)
        
        # åŠ è½½æœ¬åœ°å·²å­˜åœ¨çš„å®Œæ•´æ–‡ä»¶
        local_complete_files = set()
        for file_path in self.download_dir.glob("*"):
            if file_path.is_file() and file_path.suffix in ['.edf', '.tsv', '.atr']:
                try:
                    if file_path.stat().st_size > 100000:  # å¤§äº100KB
                        local_complete_files.add(file_path.name)
                except:
                    pass
        
        print(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {len(uploaded_files)}")
        print(f"âœ… æœ¬åœ°å®Œæ•´æ–‡ä»¶: {len(local_complete_files)}")
        
        return uploaded_files, local_complete_files

    def normalize_url(self, url_or_filename):
        """æ ‡å‡†åŒ–URLæˆ–æ–‡ä»¶å"""
        if url_or_filename.startswith('http'):
            return url_or_filename
        else:
            # åªæ˜¯æ–‡ä»¶åï¼Œæ·»åŠ åŸºç¡€URL
            return self.base_url + url_or_filename

    def load_download_tasks(self):
        """åŠ è½½ä¸‹è½½ä»»åŠ¡"""
        print("ğŸ“‹ åŠ è½½ä¸‹è½½ä»»åŠ¡...")
        
        uploaded_files, local_complete_files = self.load_existing_state()
        skip_files = uploaded_files.union(local_complete_files)
        
        # ä»å¤šä¸ªæºåŠ è½½ä»»åŠ¡
        all_urls = set()
        
        # 1. ä»group11.txtåŠ è½½
        group11_file = self.download_dir / "group11.txt"
        if group11_file.exists():
            with open(group11_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        all_urls.add(self.normalize_url(line))
        
        # 2. ä»not_downloaded.txtåŠ è½½
        if os.path.exists("not_downloaded.txt"):
            with open("not_downloaded.txt", 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        all_urls.add(self.normalize_url(line))
        
        # è¿‡æ»¤å·²å¤„ç†çš„æ–‡ä»¶
        download_tasks = []
        for url in all_urls:
            filename = url.split('/')[-1]
            if filename not in skip_files:
                download_tasks.append(url)
        
        # æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—
        for url in download_tasks:
            self.download_queue.put(url)
        
        print(f"ğŸ“¥ å¾…ä¸‹è½½ä»»åŠ¡: {len(download_tasks)}")
        return len(download_tasks)

    def load_upload_tasks(self):
        """åŠ è½½ä¸Šä¼ ä»»åŠ¡"""
        print("ğŸ“¤ åŠ è½½ä¸Šä¼ ä»»åŠ¡...")
        
        uploaded_files, _ = self.load_existing_state()
        
        upload_count = 0
        for file_path in self.download_dir.glob("*"):
            if file_path.is_file() and file_path.suffix in ['.edf', '.tsv', '.atr']:
                try:
                    if file_path.stat().st_size > 100000 and file_path.name not in uploaded_files:
                        self.upload_queue.put(file_path)
                        upload_count += 1
                except:
                    pass
        
        print(f"ğŸ“¤ å¾…ä¸Šä¼ ä»»åŠ¡: {upload_count}")
        return upload_count

    def download_file(self, url, max_retries=3):
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        filename = url.split('/')[-1]
        file_path = self.download_dir / filename
        
        for attempt in range(max_retries):
            try:
                print(f"â¬‡ï¸  ä¸‹è½½: {filename} (å°è¯• {attempt + 1}/{max_retries})")
                
                response = requests.get(url, stream=True, timeout=30)
                response.raise_for_status()
                
                total_size = int(response.headers.get('content-length', 0))
                
                with open(file_path, 'wb') as f:
                    downloaded = 0
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                
                # éªŒè¯ä¸‹è½½
                actual_size = file_path.stat().st_size
                if total_size > 0 and actual_size != total_size:
                    raise Exception(f"æ–‡ä»¶å¤§å°ä¸åŒ¹é…: {actual_size} != {total_size}")
                
                with self.stats_lock:
                    self.stats['downloaded'] += 1
                    self.stats['total_downloaded_size'] += actual_size
                
                print(f"âœ… ä¸‹è½½å®Œæˆ: {filename} ({actual_size // 1024 // 1024}MB)")
                
                # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œç«‹å³åŠ å…¥ä¸Šä¼ é˜Ÿåˆ—
                if actual_size > 100 * 1024 * 1024:  # å¤§äº100MB
                    self.upload_queue.put(file_path)
                
                return True
                
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {filename} - {e}")
                if file_path.exists():
                    file_path.unlink()
                
                if attempt == max_retries - 1:
                    self.log_failed_download(url, str(e))
                    with self.stats_lock:
                        self.stats['failed'] += 1
                    return False
                
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
        return False

    def chunked_upload_to_dropbox(self, file_path):
        """åˆ†å—ä¸Šä¼ æ–‡ä»¶åˆ°Dropbox"""
        try:
            filename = file_path.name
            file_size = file_path.stat().st_size
            dropbox_path = f"/sleep_data/{filename}"
            
            print(f"ğŸ“¤ ä¸Šä¼ : {filename} ({file_size // 1024 // 1024}MB)")
            
            with open(file_path, 'rb') as f:
                # å¼€å§‹ä¸Šä¼ ä¼šè¯
                start_response = requests.post(
                    'https://content.dropboxapi.com/2/files/upload_session/start',
                    headers={
                        'Authorization': f'Bearer {self.dropbox_token}',
                        'Dropbox-API-Arg': json.dumps({}),
                        'Content-Type': 'application/octet-stream'
                    },
                    data=f.read(self.chunk_size),
                    timeout=300
                )
                
                if start_response.status_code != 200:
                    raise Exception(f"å¼€å§‹ä¸Šä¼ å¤±è´¥: {start_response.status_code}")
                
                session_id = start_response.json()['session_id']
                offset = self.chunk_size
                
                # ä¸Šä¼ å‰©ä½™å—
                while offset < file_size:
                    remaining = file_size - offset
                    current_chunk_size = min(self.chunk_size, remaining)
                    chunk_data = f.read(current_chunk_size)
                    
                    if offset + current_chunk_size < file_size:
                        # ä¸­é—´å—
                        append_response = requests.post(
                            'https://content.dropboxapi.com/2/files/upload_session/append_v2',
                            headers={
                                'Authorization': f'Bearer {self.dropbox_token}',
                                'Dropbox-API-Arg': json.dumps({
                                    'cursor': {'session_id': session_id, 'offset': offset}
                                }),
                                'Content-Type': 'application/octet-stream'
                            },
                            data=chunk_data,
                            timeout=300
                        )
                        if append_response.status_code != 200:
                            raise Exception(f"å—ä¸Šä¼ å¤±è´¥: {append_response.status_code}")
                    else:
                        # æœ€åä¸€å—
                        finish_response = requests.post(
                            'https://content.dropboxapi.com/2/files/upload_session/finish',
                            headers={
                                'Authorization': f'Bearer {self.dropbox_token}',
                                'Dropbox-API-Arg': json.dumps({
                                    'cursor': {'session_id': session_id, 'offset': offset},
                                    'commit': {'path': dropbox_path, 'mode': 'add', 'autorename': True}
                                }),
                                'Content-Type': 'application/octet-stream'
                            },
                            data=chunk_data,
                            timeout=300
                        )
                        if finish_response.status_code != 200:
                            raise Exception(f"å®Œæˆä¸Šä¼ å¤±è´¥: {finish_response.status_code}")
                    
                    offset += current_chunk_size
                    time.sleep(0.1)  # é¿å…APIé™åˆ¶
            
            # ä¸Šä¼ æˆåŠŸï¼Œåˆ é™¤æœ¬åœ°æ–‡ä»¶å¹¶è®°å½•
            file_path.unlink()
            self.log_uploaded_file(filename)
            
            with self.stats_lock:
                self.stats['uploaded'] += 1
                self.stats['total_uploaded_size'] += file_size
            
            print(f"âœ… ä¸Šä¼ å®Œæˆå¹¶åˆ é™¤: {filename}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {file_path.name} - {e}")
            return False

    def log_uploaded_file(self, filename):
        """è®°å½•å·²ä¸Šä¼ æ–‡ä»¶"""
        with self.file_lock:
            with open(self.uploaded_log, 'a') as f:
                f.write(f"{filename}\n")

    def log_failed_download(self, url, error):
        """è®°å½•å¤±è´¥çš„ä¸‹è½½"""
        with self.file_lock:
            with open(self.failed_downloads_file, 'a') as f:
                f.write(f"{url} | {error}\n")

    def get_disk_usage(self):
        """è·å–ç£ç›˜ä½¿ç”¨æƒ…å†µ"""
        total, used, free = shutil.disk_usage("/")
        return {
            'total': total,
            'used': used,
            'free': free,
            'percent': (used / total) * 100
        }

    def download_worker(self):
        """ä¸‹è½½å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                url = self.download_queue.get(timeout=5)
                self.download_file(url)
                self.download_queue.task_done()
            except queue.Empty:
                break
            except Exception as e:
                print(f"âŒ ä¸‹è½½å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")

    def upload_worker(self):
        """ä¸Šä¼ å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                file_path = self.upload_queue.get(timeout=5)
                self.chunked_upload_to_dropbox(file_path)
                self.upload_queue.task_done()
            except queue.Empty:
                break
            except Exception as e:
                print(f"âŒ ä¸Šä¼ å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")

    def monitor_worker(self):
        """ç›‘æ§å·¥ä½œçº¿ç¨‹"""
        while True:
            time.sleep(30)  # æ¯30ç§’æŠ¥å‘Šä¸€æ¬¡
            
            disk = self.get_disk_usage()
            
            with self.stats_lock:
                print(f"\nğŸ“Š çŠ¶æ€æŠ¥å‘Š:")
                print(f"   ä¸‹è½½: {self.stats['downloaded']} ä¸ªæ–‡ä»¶ ({self.stats['total_downloaded_size'] // 1024 // 1024}MB)")
                print(f"   ä¸Šä¼ : {self.stats['uploaded']} ä¸ªæ–‡ä»¶ ({self.stats['total_uploaded_size'] // 1024 // 1024}MB)")
                print(f"   å¤±è´¥: {self.stats['failed']} ä¸ªæ–‡ä»¶")
                print(f"   ç£ç›˜: {disk['percent']:.1f}% ä½¿ç”¨ ({disk['free'] // 1024 // 1024 // 1024:.1f}GB å¯ç”¨)")
                print(f"   é˜Ÿåˆ—: ä¸‹è½½ {self.download_queue.qsize()}, ä¸Šä¼  {self.upload_queue.qsize()}")
            
            # ç£ç›˜ç©ºé—´è­¦å‘Š
            if disk['percent'] > 95:
                print("âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³ï¼æš‚åœä¸‹è½½...")
                # è¿™é‡Œå¯ä»¥å®ç°æš‚åœé€»è¾‘

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("ğŸ¯ å¯åŠ¨ Sleep Data Manager")
        
        # åŠ è½½ä»»åŠ¡
        download_tasks = self.load_download_tasks()
        upload_tasks = self.load_upload_tasks()
        
        if download_tasks == 0 and upload_tasks == 0:
            print("âœ… æ²¡æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œç¨‹åºé€€å‡º")
            return
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        
        # ä¸‹è½½çº¿ç¨‹
        for i in range(self.max_download_threads):
            t = threading.Thread(target=self.download_worker, name=f"Download-{i+1}")
            t.daemon = True
            t.start()
            threads.append(t)
        
        # ä¸Šä¼ çº¿ç¨‹
        for i in range(self.max_upload_threads):
            t = threading.Thread(target=self.upload_worker, name=f"Upload-{i+1}")
            t.daemon = True
            t.start()
            threads.append(t)
        
        # ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self.monitor_worker, name="Monitor")
        monitor_thread.daemon = True
        monitor_thread.start()
        threads.append(monitor_thread)
        
        print(f"ğŸ”„ å¯åŠ¨ {len(threads)} ä¸ªå·¥ä½œçº¿ç¨‹")
        
        try:
            # ç­‰å¾…æ‰€æœ‰ä¸‹è½½å’Œä¸Šä¼ ä»»åŠ¡å®Œæˆ
            self.download_queue.join()
            self.upload_queue.join()
            
            print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
            
            # æœ€ç»ˆç»Ÿè®¡
            with self.stats_lock:
                print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
                print(f"   ä¸‹è½½: {self.stats['downloaded']} ä¸ªæ–‡ä»¶")
                print(f"   ä¸Šä¼ : {self.stats['uploaded']} ä¸ªæ–‡ä»¶")
                print(f"   å¤±è´¥: {self.stats['failed']} ä¸ªæ–‡ä»¶")
                print(f"   æ€»ä¸‹è½½: {self.stats['total_downloaded_size'] // 1024 // 1024 // 1024:.2f}GB")
                print(f"   æ€»ä¸Šä¼ : {self.stats['total_uploaded_size'] // 1024 // 1024 // 1024:.2f}GB")
        
        except KeyboardInterrupt:
            print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
        
        except Exception as e:
            print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ Sleep Data è‡ªåŠ¨åŒ–ç®¡ç†å™¨")
    print("   åŠŸèƒ½: å¹¶è¡Œä¸‹è½½ + è‡ªåŠ¨ä¸Šä¼  + çŠ¶æ€ç®¡ç†")
    print("   ä½œè€…: AI Assistant")
    print("=" * 60)
    
    manager = SleepDataManager()
    manager.run()

if __name__ == "__main__":
    main() 