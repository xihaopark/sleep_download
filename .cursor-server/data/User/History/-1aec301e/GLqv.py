#!/usr/bin/env python3
"""
Sleep Data è‡ªåŠ¨åŒ–ç®¡ç†å™¨ - è®¤è¯ç‰ˆæœ¬
åŠŸèƒ½ï¼š
1. å¹¶è¡Œä¸‹è½½æ–‡ä»¶ï¼ˆå¸¦è®¤è¯ï¼‰
2. å¹¶è¡Œä¸Šä¼ åˆ°Dropbox
3. è‡ªåŠ¨çŠ¶æ€ç®¡ç†
4. æ™ºèƒ½é‡è¯•æœºåˆ¶
5. ç£ç›˜ç©ºé—´ç›‘æ§

ä¸€é”®æ‰§è¡Œï¼ŒåŒ…å«è®¤è¯ä¿¡æ¯
"""

import os
import sys
import threading
import time
import requests
import json
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import shutil
from requests.auth import HTTPBasicAuth

class SleepDataManagerAuth:
    def __init__(self):
        # PhysioNetè®¤è¯ä¿¡æ¯
        self.physionet_username = "chenzcha"  # ä½ çš„PhysioNetç”¨æˆ·å
        self.physionet_password = "97HU15lWcE"  # æä¾›çš„å¯†ç 
        
        # Dropboxé…ç½® - å†…ç½®ä»¤ç‰Œ
        self.dropbox_token = "sl.u.AF0ZhY-38erhzFdrLPJvKAvQL3V4tFwKeK3LFCU7CIVub5KH-lBYZJje050AZ-qDY5fTqMHdMrTQOTBph2IZPNFz2tleHtAtPUR4m16XSoSaG5vFQ1GcEySeadFY7hbtZqaYyrnxmcvT2VTR35xYo2o8xAqHIlLo3qjEe71Y0mdG80Or1g3RtPKJXkIxzO9dHqrcT_Jul3gSGuljMr6rfzNYhJUQPU_PfbbhCXXMQs_IpqYa7wawSSuXtS2SLrxmoYfPFSaAhmKIDv4N7qale0AOHdjuh5-e8p5WDwdE_JqSJCbsSZlmGl-t0O3UsxHaMGjCoqy3MpDVYR2_XOPEWheLPrbKIwao6_2KKLrxvh--5oKlgE1NG4da1EVwGSQMK7g5rYHZkg1yEnWP5fHyLU8VOT8fdC6e5FIcKIC6HnvDmwzF0MTEnxkFGU9NQW5GULvDBTI8CFXRhg9sAK6StvwCft_uEtbpe1Piu3sG_AVd12G7R_wJggInGRWyN3SQBoGK5Lmtey5YWhTPvBXw-aqE37XYFJuC3VQl06cbVOIdrMi33YhdeoMiB3eLBCUt6H2Te619LzG_b6jixmH1nHmvyVcp4vGHUbNd8b_R8ffd2VooeX8UyDUAGZiYbSn4czgNGLoiPa_g7NG3RCeKz1JevcTbnQd_ynFhSs2eYonkIosSDy8XGuwXuLKvqPkH77NTerLNx8ogzk-Dy-a_E4XbZSSf9GrMGVOqr2NKk2yAmUoK6E4pZ_T6ZFAP6UKhJQJd0YPEHHD5sDY-2uJJccWlzVkN62qY_Z6GNVB94raiQEkxPSCea4Pcd9SxdKSmedEbXtCffKPYqp2BgEWpwfI_VcYegzO4dmu-35GwArPIWRmdHRG_WcYr9zUMo1gKapiHDDRutEY8BAgtN9BUs17an9dI20fSaKexBC4c7TQ-TxxpqOPsDOXgrKLZQrB7CXplfnlJZwb7L8LWS8LrIqmLhPp8F-WfiQSAGm-qdGCAmVmFqk_FeBGp9CTbe5dVx256JX-Bg56Napz15BohD6cZCoTlv5PpPBrHCx_tRYysd3MF4NYTuu5Zpnsjg5C9WetPGB_W1GLfh4QKPB70OCXRhCPM290VRn5rotm0t7c3_DFxI6fodsZ8R18xfFSnN7yg-hn9-iEHvb69K2havWfp4KQY_MCXBE8BnDFVvN6C5wNsuOnzu0MJUP4vdwhRYc54ZOeJjxtanaOcWXGlWhq9uoFhSqRM1cdjoTUxTTEqZG799fgPfFj-JNNjJHEQe-j-iZGOMYAm8ZCp8MU97V99-gXguu6kUMAYpAUUVpMumg"
        
        # è·¯å¾„é…ç½®
        self.download_dir = Path("download")
        self.download_dir.mkdir(exist_ok=True)
        
        # çŠ¶æ€æ–‡ä»¶
        self.uploaded_log = "uploaded_files.txt"
        self.download_queue_file = "download_queue.txt"
        self.failed_downloads_file = "failed_downloads.txt"
        self.success_log = "download_success.txt"
        
        # å¹¶å‘é…ç½®
        self.max_download_threads = 4
        self.max_upload_threads = 2
        self.chunk_size = 100 * 1024 * 1024  # 100MB chunks
        
        # åŸºç¡€URL
        self.base_url = "https://physionet.org/files/nch-sleep/3.1.0/Sleep_Data/"
        
        # é˜Ÿåˆ—
        self.download_queue = queue.Queue()
        self.upload_queue = queue.Queue()
        
        # ç»Ÿè®¡
        self.stats = {
            'downloaded': 0,
            'uploaded': 0,
            'failed': 0,
            'skipped': 0,
            'total_downloaded_size': 0,
            'total_uploaded_size': 0
        }
        
        # é”
        self.stats_lock = threading.Lock()
        self.file_lock = threading.Lock()
        
        print("ğŸš€ Sleep Data Manager (è®¤è¯ç‰ˆ) åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ” ä½¿ç”¨è®¤è¯: {self.physionet_username}")

    def load_existing_state(self):
        """åŠ è½½ç°æœ‰çŠ¶æ€"""
        print("ğŸ“Š åŠ è½½ç°æœ‰çŠ¶æ€...")
        
        # åŠ è½½å·²ä¸Šä¼ æ–‡ä»¶
        uploaded_files = set()
        if os.path.exists(self.uploaded_log):
            with open(self.uploaded_log, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        uploaded_files.add(line)
        
        # åŠ è½½å·²æˆåŠŸä¸‹è½½çš„æ–‡ä»¶
        downloaded_files = set()
        if os.path.exists(self.success_log):
            with open(self.success_log, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        downloaded_files.add(line)
        
        # åŠ è½½æœ¬åœ°å·²å­˜åœ¨çš„å®Œæ•´æ–‡ä»¶
        local_complete_files = set()
        for file_path in self.download_dir.glob("*"):
            if file_path.is_file() and file_path.suffix in ['.edf', '.tsv', '.atr']:
                try:
                    if file_path.stat().st_size > 10000:  # å¤§äº10KB
                        local_complete_files.add(file_path.name)
                except:
                    pass
        
        print(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {len(uploaded_files)}")
        print(f"âœ… å·²ä¸‹è½½æ–‡ä»¶: {len(downloaded_files)}")
        print(f"âœ… æœ¬åœ°å®Œæ•´æ–‡ä»¶: {len(local_complete_files)}")
        
        return uploaded_files, downloaded_files, local_complete_files

    def normalize_url(self, url_or_filename):
        """æ ‡å‡†åŒ–URLæˆ–æ–‡ä»¶å"""
        if url_or_filename.startswith('http'):
            return url_or_filename
        else:
            # åªæ˜¯æ–‡ä»¶åï¼Œæ·»åŠ åŸºç¡€URL
            return self.base_url + url_or_filename

    def load_download_tasks(self):
        """åŠ è½½ä¸‹è½½ä»»åŠ¡"""
        print("ğŸ“‹ åŠ è½½ä¸‹è½½ä»»åŠ¡...")
        
        uploaded_files, downloaded_files, local_complete_files = self.load_existing_state()
        skip_files = uploaded_files.union(downloaded_files).union(local_complete_files)
        
        # ä»å¤šä¸ªæºåŠ è½½ä»»åŠ¡
        all_urls = set()
        
        # 1. ä»group11.txtåŠ è½½
        group11_file = self.download_dir / "group11.txt"
        if group11_file.exists():
            with open(group11_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        all_urls.add(self.normalize_url(line))
        
        # 2. ä»not_downloaded.txtåŠ è½½
        if os.path.exists("not_downloaded.txt"):
            with open("not_downloaded.txt", 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        all_urls.add(self.normalize_url(line))
        
        # è¿‡æ»¤å·²å¤„ç†çš„æ–‡ä»¶
        download_tasks = []
        for url in all_urls:
            filename = url.split('/')[-1]
            if filename not in skip_files:
                download_tasks.append(url)
        
        # ä¼˜å…ˆä¸‹è½½EDFæ–‡ä»¶ï¼ˆå¤§æ–‡ä»¶ï¼‰
        edf_tasks = [url for url in download_tasks if url.endswith('.edf')]
        other_tasks = [url for url in download_tasks if not url.endswith('.edf')]
        
        # æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—
        for url in edf_tasks + other_tasks:
            self.download_queue.put(url)
        
        print(f"ğŸ“¥ å¾…ä¸‹è½½ä»»åŠ¡: {len(download_tasks)} (EDF: {len(edf_tasks)}, å…¶ä»–: {len(other_tasks)})")
        return len(download_tasks)

    def load_upload_tasks(self):
        """åŠ è½½ä¸Šä¼ ä»»åŠ¡"""
        print("ğŸ“¤ åŠ è½½ä¸Šä¼ ä»»åŠ¡...")
        
        uploaded_files, _, _ = self.load_existing_state()
        
        upload_count = 0
        upload_tasks = []
        
        for file_path in self.download_dir.glob("*"):
            if file_path.is_file() and file_path.suffix in ['.edf', '.tsv', '.atr']:
                try:
                    if file_path.stat().st_size > 10000 and file_path.name not in uploaded_files:
                        upload_tasks.append((file_path, file_path.stat().st_size))
                        upload_count += 1
                except:
                    pass
        
        # æŒ‰æ–‡ä»¶å¤§å°æ’åºï¼Œä¼˜å…ˆä¸Šä¼ å¤§æ–‡ä»¶
        upload_tasks.sort(key=lambda x: x[1], reverse=True)
        
        for file_path, _ in upload_tasks:
            self.upload_queue.put(file_path)
        
        print(f"ğŸ“¤ å¾…ä¸Šä¼ ä»»åŠ¡: {upload_count}")
        return upload_count

    def download_file(self, url, max_retries=3):
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼ˆå¸¦è®¤è¯ï¼‰"""
        filename = url.split('/')[-1]
        file_path = self.download_dir / filename
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
        resume_pos = 0
        if file_path.exists():
            try:
                resume_pos = file_path.stat().st_size
                if resume_pos > 10000:
                    # å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®Œæ•´
                    print(f"ğŸ” æ£€æŸ¥å·²å­˜åœ¨æ–‡ä»¶: {filename} ({resume_pos // 1024 // 1024}MB)")
                    
                    # å‘é€HEADè¯·æ±‚è·å–æ–‡ä»¶å¤§å°
                    auth = HTTPBasicAuth(self.physionet_username, self.physionet_password)
                    head_response = requests.head(url, auth=auth, timeout=30)
                    if head_response.status_code == 200:
                        total_size = int(head_response.headers.get('content-length', 0))
                        if total_size > 0 and resume_pos >= total_size:
                            print(f"âœ… æ–‡ä»¶å·²å®Œæ•´: {filename}")
                            with self.stats_lock:
                                self.stats['skipped'] += 1
                            return True
                        elif total_size > 0 and resume_pos > 0:
                            print(f"ğŸ“¥ æ–­ç‚¹ç»­ä¼ : {filename} (ä» {resume_pos // 1024 // 1024}MB å¼€å§‹)")
            except:
                resume_pos = 0
        
        for attempt in range(max_retries):
            try:
                print(f"â¬‡ï¸  ä¸‹è½½: {filename} (å°è¯• {attempt + 1}/{max_retries})")
                
                # ä½¿ç”¨è®¤è¯ä¿¡æ¯ï¼Œæ¨¡æ‹Ÿwgetè¡Œä¸º
                auth = HTTPBasicAuth(self.physionet_username, self.physionet_password)
                
                response = requests.get(
                    url, 
                    stream=True, 
                    timeout=300,  # 300ç§’è¶…æ—¶ï¼Œå¯¹åº”wget --timeout=300
                    auth=auth,
                    headers={
                        'User-Agent': 'Wget/1.20.3 (linux-gnu)',  # æ¨¡æ‹Ÿwget
                        'Accept': '*/*',
                        'Accept-Encoding': 'identity',
                        'Connection': 'Keep-Alive'
                    },
                    allow_redirects=True
                )
                response.raise_for_status()
                
                total_size = int(response.headers.get('content-length', 0))
                
                with open(file_path, 'wb') as f:
                    downloaded = 0
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                
                # éªŒè¯ä¸‹è½½
                actual_size = file_path.stat().st_size
                if total_size > 0 and abs(actual_size - total_size) > 1024:  # å…è®¸1KBè¯¯å·®
                    raise Exception(f"æ–‡ä»¶å¤§å°ä¸åŒ¹é…: {actual_size} != {total_size}")
                
                with self.stats_lock:
                    self.stats['downloaded'] += 1
                    self.stats['total_downloaded_size'] += actual_size
                
                # è®°å½•æˆåŠŸä¸‹è½½
                self.log_successful_download(filename)
                
                print(f"âœ… ä¸‹è½½å®Œæˆ: {filename} ({actual_size // 1024 // 1024}MB)")
                
                # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œç«‹å³åŠ å…¥ä¸Šä¼ é˜Ÿåˆ—
                if actual_size > 50 * 1024 * 1024:  # å¤§äº50MB
                    self.upload_queue.put(file_path)
                
                return True
                
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {filename} - {e}")
                if file_path.exists():
                    file_path.unlink()
                
                if attempt == max_retries - 1:
                    self.log_failed_download(url, str(e))
                    with self.stats_lock:
                        self.stats['failed'] += 1
                    return False
                
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
        return False

    def chunked_upload_to_dropbox(self, file_path):
        """åˆ†å—ä¸Šä¼ æ–‡ä»¶åˆ°Dropbox"""
        try:
            filename = file_path.name
            file_size = file_path.stat().st_size
            dropbox_path = f"/sleep_data/{filename}"
            
            print(f"ğŸ“¤ ä¸Šä¼ : {filename} ({file_size // 1024 // 1024}MB)")
            
            with open(file_path, 'rb') as f:
                # å¼€å§‹ä¸Šä¼ ä¼šè¯
                start_response = requests.post(
                    'https://content.dropboxapi.com/2/files/upload_session/start',
                    headers={
                        'Authorization': f'Bearer {self.dropbox_token}',
                        'Dropbox-API-Arg': json.dumps({}),
                        'Content-Type': 'application/octet-stream'
                    },
                    data=f.read(self.chunk_size),
                    timeout=300
                )
                
                if start_response.status_code != 200:
                    raise Exception(f"å¼€å§‹ä¸Šä¼ å¤±è´¥: {start_response.status_code}")
                
                session_id = start_response.json()['session_id']
                offset = self.chunk_size
                
                # ä¸Šä¼ å‰©ä½™å—
                while offset < file_size:
                    remaining = file_size - offset
                    current_chunk_size = min(self.chunk_size, remaining)
                    chunk_data = f.read(current_chunk_size)
                    
                    if offset + current_chunk_size < file_size:
                        # ä¸­é—´å—
                        append_response = requests.post(
                            'https://content.dropboxapi.com/2/files/upload_session/append_v2',
                            headers={
                                'Authorization': f'Bearer {self.dropbox_token}',
                                'Dropbox-API-Arg': json.dumps({
                                    'cursor': {'session_id': session_id, 'offset': offset}
                                }),
                                'Content-Type': 'application/octet-stream'
                            },
                            data=chunk_data,
                            timeout=300
                        )
                        if append_response.status_code != 200:
                            raise Exception(f"å—ä¸Šä¼ å¤±è´¥: {append_response.status_code}")
                    else:
                        # æœ€åä¸€å—
                        finish_response = requests.post(
                            'https://content.dropboxapi.com/2/files/upload_session/finish',
                            headers={
                                'Authorization': f'Bearer {self.dropbox_token}',
                                'Dropbox-API-Arg': json.dumps({
                                    'cursor': {'session_id': session_id, 'offset': offset},
                                    'commit': {'path': dropbox_path, 'mode': 'add', 'autorename': True}
                                }),
                                'Content-Type': 'application/octet-stream'
                            },
                            data=chunk_data,
                            timeout=300
                        )
                        if finish_response.status_code != 200:
                            raise Exception(f"å®Œæˆä¸Šä¼ å¤±è´¥: {finish_response.status_code}")
                    
                    offset += current_chunk_size
                    time.sleep(0.1)  # é¿å…APIé™åˆ¶
            
            # ä¸Šä¼ æˆåŠŸï¼Œåˆ é™¤æœ¬åœ°æ–‡ä»¶å¹¶è®°å½•
            file_path.unlink()
            self.log_uploaded_file(filename)
            
            with self.stats_lock:
                self.stats['uploaded'] += 1
                self.stats['total_uploaded_size'] += file_size
            
            print(f"âœ… ä¸Šä¼ å®Œæˆå¹¶åˆ é™¤: {filename}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¸Šä¼ å¤±è´¥: {file_path.name} - {e}")
            return False

    def log_uploaded_file(self, filename):
        """è®°å½•å·²ä¸Šä¼ æ–‡ä»¶"""
        with self.file_lock:
            with open(self.uploaded_log, 'a') as f:
                f.write(f"{filename}\n")

    def log_successful_download(self, filename):
        """è®°å½•æˆåŠŸä¸‹è½½çš„æ–‡ä»¶"""
        with self.file_lock:
            with open(self.success_log, 'a') as f:
                f.write(f"{filename}\n")

    def log_failed_download(self, url, error):
        """è®°å½•å¤±è´¥çš„ä¸‹è½½"""
        with self.file_lock:
            with open(self.failed_downloads_file, 'a') as f:
                f.write(f"{url} | {error}\n")

    def get_disk_usage(self):
        """è·å–ç£ç›˜ä½¿ç”¨æƒ…å†µ"""
        total, used, free = shutil.disk_usage("/")
        return {
            'total': total,
            'used': used,
            'free': free,
            'percent': (used / total) * 100
        }

    def download_worker(self):
        """ä¸‹è½½å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                url = self.download_queue.get(timeout=10)
                
                # æ£€æŸ¥ç£ç›˜ç©ºé—´
                disk = self.get_disk_usage()
                if disk['percent'] > 90:
                    print(f"âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³ ({disk['percent']:.1f}%)ï¼Œæš‚åœä¸‹è½½")
                    self.download_queue.put(url)  # æ”¾å›é˜Ÿåˆ—
                    time.sleep(30)
                    continue
                
                self.download_file(url)
                self.download_queue.task_done()
                
            except queue.Empty:
                break
            except Exception as e:
                print(f"âŒ ä¸‹è½½å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")

    def upload_worker(self):
        """ä¸Šä¼ å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                file_path = self.upload_queue.get(timeout=10)
                self.chunked_upload_to_dropbox(file_path)
                self.upload_queue.task_done()
            except queue.Empty:
                break
            except Exception as e:
                print(f"âŒ ä¸Šä¼ å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")

    def monitor_worker(self):
        """ç›‘æ§å·¥ä½œçº¿ç¨‹"""
        while True:
            time.sleep(60)  # æ¯60ç§’æŠ¥å‘Šä¸€æ¬¡
            
            disk = self.get_disk_usage()
            
            with self.stats_lock:
                print(f"\nğŸ“Š çŠ¶æ€æŠ¥å‘Š [{time.strftime('%H:%M:%S')}]:")
                print(f"   ä¸‹è½½: {self.stats['downloaded']} ä¸ªæ–‡ä»¶ ({self.stats['total_downloaded_size'] // 1024 // 1024}MB)")
                print(f"   ä¸Šä¼ : {self.stats['uploaded']} ä¸ªæ–‡ä»¶ ({self.stats['total_uploaded_size'] // 1024 // 1024}MB)")
                print(f"   è·³è¿‡: {self.stats['skipped']} ä¸ªæ–‡ä»¶")
                print(f"   å¤±è´¥: {self.stats['failed']} ä¸ªæ–‡ä»¶")
                print(f"   ç£ç›˜: {disk['percent']:.1f}% ä½¿ç”¨ ({disk['free'] // 1024 // 1024 // 1024:.1f}GB å¯ç”¨)")
                print(f"   é˜Ÿåˆ—: ä¸‹è½½ {self.download_queue.qsize()}, ä¸Šä¼  {self.upload_queue.qsize()}")
                print("-" * 60)

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("ğŸ¯ å¯åŠ¨ Sleep Data Manager (è®¤è¯ç‰ˆ)")
        
        # åŠ è½½ä»»åŠ¡
        download_tasks = self.load_download_tasks()
        upload_tasks = self.load_upload_tasks()
        
        if download_tasks == 0 and upload_tasks == 0:
            print("âœ… æ²¡æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œç¨‹åºé€€å‡º")
            return
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        
        # ä¸‹è½½çº¿ç¨‹
        for i in range(self.max_download_threads):
            t = threading.Thread(target=self.download_worker, name=f"Download-{i+1}")
            t.daemon = True
            t.start()
            threads.append(t)
        
        # ä¸Šä¼ çº¿ç¨‹
        for i in range(self.max_upload_threads):
            t = threading.Thread(target=self.upload_worker, name=f"Upload-{i+1}")
            t.daemon = True
            t.start()
            threads.append(t)
        
        # ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self.monitor_worker, name="Monitor")
        monitor_thread.daemon = True
        monitor_thread.start()
        threads.append(monitor_thread)
        
        print(f"ğŸ”„ å¯åŠ¨ {len(threads)} ä¸ªå·¥ä½œçº¿ç¨‹")
        print(f"ğŸ“¥ ä¸‹è½½é˜Ÿåˆ—: {download_tasks} ä¸ªä»»åŠ¡")
        print(f"ğŸ“¤ ä¸Šä¼ é˜Ÿåˆ—: {upload_tasks} ä¸ªä»»åŠ¡")
        
        try:
            # ç­‰å¾…æ‰€æœ‰ä¸‹è½½å’Œä¸Šä¼ ä»»åŠ¡å®Œæˆ
            self.download_queue.join()
            self.upload_queue.join()
            
            print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
            
            # æœ€ç»ˆç»Ÿè®¡
            with self.stats_lock:
                print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
                print(f"   ä¸‹è½½: {self.stats['downloaded']} ä¸ªæ–‡ä»¶")
                print(f"   ä¸Šä¼ : {self.stats['uploaded']} ä¸ªæ–‡ä»¶")
                print(f"   è·³è¿‡: {self.stats['skipped']} ä¸ªæ–‡ä»¶")
                print(f"   å¤±è´¥: {self.stats['failed']} ä¸ªæ–‡ä»¶")
                print(f"   æ€»ä¸‹è½½: {self.stats['total_downloaded_size'] // 1024 // 1024 // 1024:.2f}GB")
                print(f"   æ€»ä¸Šä¼ : {self.stats['total_uploaded_size'] // 1024 // 1024 // 1024:.2f}GB")
        
        except KeyboardInterrupt:
            print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
        
        except Exception as e:
            print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸš€ Sleep Data è‡ªåŠ¨åŒ–ç®¡ç†å™¨ - è®¤è¯ç‰ˆ")
    print("   åŠŸèƒ½: å¹¶è¡Œä¸‹è½½(å¸¦è®¤è¯) + è‡ªåŠ¨ä¸Šä¼  + çŠ¶æ€ç®¡ç†")
    print("   è®¤è¯: PhysioNet + Dropbox")
    print("   ä½œè€…: AI Assistant")
    print("=" * 70)
    
    manager = SleepDataManagerAuth()
    manager.run()

if __name__ == "__main__":
    main() 